MODEL:
  # NAME: "math_enc_old"
  NAME: "fuse"
  BERT:
    ADD_POOLING: false
    REDUCE_DIM: false
    DIM: 128
    MAX_SEQ_LEN: 512
  MATH_ENC:
    TOK_EMB: "bert"
    VOCAB_SIZE: null
    DIM: 768
    N_LAYERS: 8
    N_HEADS: 12
    N_KV_HEADS: 12
    BASE: 10000
    MULTIPLE_OF: 256
    FFN_DIM_MULTIPLIER: null
    NORM_EPS: 1e-5
    THETA: 10000
    MAX_SEQ_LEN: 256

CKPT:
  DIR:  "ckpt/transformer"
  BEST: "ckpt/transformer/best.ckpt"
  # LAST: "ckpt/transformer/last.ckpt"
  LAST: "ckpt/transformer/avgpool_16M.ckpt"
  BERT:
    CFG: "ckpt/bert/config.json"
    MODEL: "ckpt/bert/bert.ckpt"
    TOKENIZER: "ckpt/bert/bert-tokenizer-for-math-v2"
  FUSE: "ckpt/fuse/fuse.ckpt"
  MATH_ENC:
    PRETRAIN: null

OPTIM:
  NAME: "adamw"
  BASE_LR: 1e-4
  WARMUP_LR: 1e-7
  MIN_LR: 1e-6

  SGD:
    MOMENTUM: 0.90
    WEIGHT_DECAY: 1e-4
    NESTEROV: true
  ADAMW:
    BETAS: [0.9, 0.999]
    EPS: 1e-8
    WEIGHT_DECAY: 0.01

LRS:
  NAME: "cosine"
  STEP_LRS:
    DECAY_RATE: 0.1

CRITERION:
  NAME: "maxsim"
  INFONCE:
    TEMPERATURE: 0.1
    REDUCTION: "mean"
  MAXSIM:
    TEMPERATURE: 0.1
    REDUCTION: "mean"

POSTPROCESS:
  NAME: "maxsim"

LOADER:
  TRAIN:
    BATCH_SIZE: 16
    SHUFFLE: true
    NUM_WORKERS: 1
    PIN_MEMORY: true

TRAIN:
  DECAY_EPOCHS: 3
  MAX_NORM: 1.0
  N_ITER_PER_EPOCH: 312500
  WARMUP_EPOCHS: 0.016
  N_EPOCHS: 3
  SAVE_N_ITERS: 1000
  STATS_FILEPATH: "stats.json"
